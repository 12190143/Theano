
.. _omlw2014_index:

===========================
Theano Tutorial @ OMLW 2014
===========================

August 22, 2014, New York University, US.

This presentation will talk about Theano, Pylearn2  software stack for
machine learning.

It complements the Python numeric/scientific software stack (e.g. NumPy, SciPy,
scikits, matplotlib, PIL.)

Theano
======

Theano is a software for evaluating and manipulating complicated array
expressions.

What does it do?

 * aggressive expression optimizations,

 * automatic GPU use,

 * automatic symbolic differentiation, Jacobian, Hession computation
   and R/L op (for hessian free).

Design and feature set has been driven by machine learning research
at the University of
Montreal (groups of Yoshua Bengio, Pascal Vincent, Aaron Courville and Roland Memisevic)
The result is a very good library for doing research in deep
learning and neural network training, and a flexible framework for
many other models and algorithms in machine learning more generally.

# TODO UPDATE
It has proven to be useful for implementing:

 - linear and nonlinear neural network classifiers

 - convolutional models

 - Energy models: RBM, DBN, GRBM, ssRBM, AIS

 - Auto-encoders: DAE, CAE

 - GP regression

 - sparse coding

 - recurrent neural networks, echo state, (HMM?)

 - online and batch learning and optimization

 - Even SVM!

As people's needs change this list will grow, but Theano is built
around vector, matrix, and tensor expressions; there is little reason
to use it for calculations on other data structures except. There is
also sparse matrix support.


Pylearn2
========

Pylearn2 is still undergoing rapid development. Donâ€™t expect a clean
road without bumps! It is made for machine learning
practitioner/researcher first.

Pylearn2 is a machine learning library. Most of its functionality is
built on top of Theano. This means you can write Pylearn2 plugins (new
models, algorithms, etc) using mathematical expressions, and Theano
will optimize and stabilize those expressions for you, and compile
them to a backend of your choice (CPU or GPU).


Pylearn2 Vision
---------------

* Researchers add features as they need them. We avoid getting bogged down by
  too much top-down planning in advance.
* A machine learning toolbox for easy scientific experimentation.
* All models/algorithms published by the LISA lab should have reference
  implementations in Pylearn2.
* Pylearn2 may wrap other libraries such as scikits.learn when this is practical
* Pylearn2 differs from scikits.learn in that Pylearn2 aims to provide great
  flexibility and make it possible for a researcher to do almost anything,
  while scikits.learn aims to work as a "black box" that can produce good
  results even if the user does not understand the implementation
* Dataset interface for vector, images, video, ...
* Small framework for all what is needed for one normal MLP/RBM/SDA/Convolution
  experiments.
* *Easy reuse* of sub-component of Pylearn2.
* Using one sub-component of the library does not force you to use / learn to
  use all of the other sub-components if you choose not to.
* Support cross-platform serialization of learned models.
* Remain approachable enough to be used in the classroom


Contents
========

The structured part of these lab sessions will be a walk-through of the following
material. Interleaved with this structured part will be blocks of time for
individual or group work.  The idea is that you can try out Theano and get help
from gurus on hand if you get stuck.

.. toctree::

    introduction
    theano
    pylearn2
    gpundarray
    sharing
